{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implicit baseline\n",
    "Более подробно [почитать](https://github.com/benfred/implicit) про библиотеку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import implicit\n",
    "\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add zeros to k items length\n",
    "def add_to_k(lst, k):\n",
    "    return lst + [0] * max(k - len(lst), 0)\n",
    "\n",
    "# precision at k\n",
    "def precision_at_k(r_true_arr, k):\n",
    "    return np.sum(r_true_arr[:k]) / k\n",
    "\n",
    "\n",
    "# average precision at k\n",
    "def average_precision_at_k(r_true_arr, k):\n",
    "    apk = 0\n",
    "    for n in range(0, k):\n",
    "        apk += precision_at_k(r_true_arr, n + 1) * r_true_arr[n]\n",
    "    if np.sum(r_true_arr[:k]) != 0:\n",
    "        return (apk) / k\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "# average normed precision at k\n",
    "def average_normed_precision_at_k(r_true_arr, k, n_true):\n",
    "    apk = 0\n",
    "    apk_ideal = n_true / k\n",
    "    \n",
    "    for n in range(0, k):\n",
    "        apk += precision_at_k(r_true_arr, n + 1) * r_true_arr[n]\n",
    "    if np.sum(r_true_arr[:k]) != 0:\n",
    "        return ((apk) / k) / apk_ideal\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enumerated_dict(values):\n",
    "    enum_dict = {}\n",
    "    reverse_dict = {}\n",
    "    \n",
    "    for n, value in enumerate(values):\n",
    "        enum_dict[value] = n\n",
    "        reverse_dict[n] = value\n",
    "        \n",
    "    return enum_dict, reverse_dict\n",
    "\n",
    "\n",
    "def predict_user(model, user_id, products, product_dict, reverse_product_dict, matrix_shape):\n",
    "    enum_clients = np.zeros(len(products))\n",
    "    enum_products = np.array([product_dict[product] for product in products])\n",
    "\n",
    "    sparse_matrix = scipy.sparse.csr_matrix((np.ones(shape=(len(enum_clients))), \n",
    "                                             (enum_clients, enum_products)), \n",
    "                                            shape=matrix_shape)\n",
    "    \n",
    "    rec = model.recommend(0, sparse_matrix, N=30, recalculate_user=True,\n",
    "                     filter_already_liked_items=False)\n",
    "    \n",
    "    return [[user_id, reverse_product_dict[r[0]]] for r in rec]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_purchases = pd.read_csv(\"../retailhero-uplift/data/purchases.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# выберем только пользователей с более, чем одной транзакцией\n",
    "transactions_cnt = df_purchases\\\n",
    "                    .groupby(by=[\"client_id\"])[\"transaction_id\"]\\\n",
    "                    .count()\\\n",
    "                    .reset_index()\n",
    "\n",
    "multi_trans_users = transactions_cnt[transactions_cnt[\"transaction_id\"] > 1][\"client_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_users = np.random.choice(multi_trans_users, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = df_purchases[~df_purchases[\"client_id\"].isin(test_users)], \\\n",
    "              df_purchases[df_purchases[\"client_id\"].isin(test_users)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_transactions = test.drop_duplicates(subset=\"client_id\", keep=\"last\")[\"transaction_id\"]\n",
    "test_data = test[~test[\"transaction_id\"].isin(last_transactions)]\n",
    "test_validation = test[test[\"transaction_id\"].isin(last_transactions)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# клиенты только из train, а продукты из всего набора данных\n",
    "client_dict, reverse_client_dict = enumerated_dict(df_purchases[\"client_id\"].unique())\n",
    "product_dict, reverse_product_dict = enumerated_dict(df_purchases[\"product_id\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определим размер матрицы\n",
    "matrix_shape = (max(reverse_client_dict.keys()) + 1, max(reverse_product_dict.keys()) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparticity:  99.99730966188883\n"
     ]
    }
   ],
   "source": [
    "enum_clients = np.array([client_dict[client] for client in train[\"client_id\"]])\n",
    "enum_products = np.array([product_dict[product] for product in train[\"product_id\"]])\n",
    "\n",
    "sparse_matrix = scipy.sparse.coo_matrix((np.ones(shape=(len(enum_clients))), \n",
    "                                         (enum_clients, enum_products)), \n",
    "                                        shape=matrix_shape)\n",
    "print(\"Sparticity: \", 100 - df_purchases.shape[0] / \\\n",
    "        (sparse_matrix.shape[0] * sparse_matrix.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa97cd408f894a8dbc0873764ebf92d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=42530), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize model\n",
    "model = implicit.nearest_neighbours.TFIDFRecommender(K=50)\n",
    "\n",
    "# Fit model\n",
    "model.fit((sparse_matrix.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b16cb36a53984456bd4c6c79fe30af88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=983), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Рекомендации для отсутствующих пользователей\n",
    "recommendations = []\n",
    "\n",
    "for test_client in tqdm_notebook(test_data[\"client_id\"].unique()):\n",
    "    products = test_data[test_data[\"client_id\"]==test_client][\"product_id\"]\n",
    "    rec = predict_user(model, test_client, products, product_dict, reverse_product_dict,\n",
    "                       (1, matrix_shape[1]))\n",
    "    recommendations.extend(rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "# датафрейм с покупками в реальности\n",
    "reality = test_validation[[\"client_id\", \"product_id\"]].copy()\n",
    "reality.loc[:, \"is_buyed\"] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics (precision@30, avg_precision@30, average_normed_precision@30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_df = pd.DataFrame(recommendations, columns=[\"client_id\", \"product_id\"])\\\n",
    "            .merge(reality, \n",
    "                   on=[\"client_id\", \"product_id\"], \n",
    "                   how=\"left\", \n",
    "                   sort=False)\\\n",
    "            .fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "# словарь с количеством покупок на валидации\n",
    "real_dict = reality.groupby(by=\"client_id\")[\"is_buyed\"].sum().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04706680230586639"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([precision_at_k(i, 30) for i in \n",
    "         rec_df.groupby(by=\"client_id\", sort=False)[\"is_buyed\"].apply(list)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.021161332606648455"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([average_precision_at_k(add_to_k(i, 30), 30) for client, i in \n",
    "         rec_df.groupby(by=\"client_id\")[\"is_buyed\"].apply(list).reset_index().values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09907394880846197"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([average_normed_precision_at_k(add_to_k(i, 30), 30, real_dict.get(client, 0)) for client, i in \n",
    "         rec_df.groupby(by=\"client_id\")[\"is_buyed\"].apply(list).reset_index().values])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Сохраняем нашу модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сохраняем помимо модели еще и словари, чтобы была возможность создать матрицу\n",
    "with open(\"x5_implicit.pkl\", \"wb\") as f:\n",
    "    pickle.dump((model, client_dict, reverse_client_dict, \n",
    "                 product_dict, reverse_product_dict), f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Итого:\n",
    "1. Мы обучили  из библиотеки implicit;\n",
    "2. Сделали валидационное и обучающее множества, получив на валидации результаты:\n",
    "    - average_precision_at_k: 0.021\n",
    "    - average_normed_precision_at_k: 0.099\n",
    "3. Сохранили модель и использовали ее в решении;\n",
    "4. Получили следующие результаты при загрузке нашего ответа:\n",
    "    - check: 0.0938\n",
    "    - public: 0.0908"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imlicit",
   "language": "python",
   "name": "imlicit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
